\chapter{Implementation}
In this chapter the implementation steps are introduced of the system described in 
\ref{chap:system_design}. Two LIDAR sensors are placed on a simulated quadcopter in Gazebo, 
that cover the top and bottom hemispheres around the drone. Using the data collected in the
simulator, these range measurements are filtered to simulate a number of VL53L1X sensors with 
a predefined operating modes and orientations. 

In order to simulate the VL53L1X sensors accurately a set of parameters, capabilities and 
limitations of the LIDAR sensor is measured. Data is collected using selected operating modes
on selected distances that are described in \ref{sect:vl53l1x_measurements}. Average distance,
standard deviation, sampling rate and typical range status are extracted. 

The two main components in the evaluation of VL53L1X sensor are a microcontroller and a PC. The 
microcontroller communicates with the sensor and sends the raw measurements to the PC that runs 
data processing and evaluates the received data. I chose to separate data collection and processing,
because data processing is significantly easier in high level programming languages, like Python and 
is much easier to adjust.It also enables data collection and offline processing.


\section{VL53L1X measurement setup}
For each measurement a combination of parameters need to be configured on VL53L1X, these are the 
timing budget, resolution and distance preset. The configuration is done via I2C protocol by the
microcontroller. VL53L1 API from STMicroelectronics is used for interfacing the sensor with the most
recent version at the time: 2.3.3. After completing boot the recommended initialization steps are 
used, as described in example codes and the API user manual \cite{VL53L1XAPIManual}.

Each measurement is triggered in single shot mode, that means exactly one ranging is done by the 
sensor and afterwards it waits until a new command arrives.  Single shot is preferred over continuous
measurements, because if the resolution is set to higher than 1x1, measurements need to be done on 
multiple ROIs and ROI has to be configured before triggering each measurement. In continuous mode 
the ROI cannot be modified between measurements.
A scan is complete if ranges are done on all ROIs of interest. The completed scan is then forwarded 
for processing to the PC via USB-CDC protocol.

\begin{figure}[ht]
    \centering
    \includegraphics[width=130mm, keepaspectratio]{figures/vl53l1x_workflow.png}
    \caption{VL53L1X measurement workflow}
    \label{fig:vl53l1x_workflow}
\end{figure}


I chose Python as a programming language to read data from USB-CDC protocol and process the incoming
data, because Python is rich in data processing tools and enables quick development. The script first
reads 50 scans coming from the MCU, then closes communication and works on the collected data. 
The features extracted area the average distance, standard deviation, typical range status and sampling
time. Average and standard deviation are calculated based on the whole population as in equations 
\ref{eq:avg} and \ref{eq:std}, where s and r are the indices of scan and range, S and R are the 
number of scans and ranges accordingly.

\begin{equation} \label{eq:avg}
    d_{avg}=\frac{1}{S \cdot R}\sum_{s=0}^S{\sum_{r=0}^R{d_{sr}} } 
\end{equation}

\begin{equation} \label{eq:std}
    d_{std}=\sqrt{ \frac{1}{S\cdot R}\sum_{s=0}^S{ \sum_{r=0}^R{ (d_{sr} -d_{avg}})^2 }}
\end{equation}


\subsection{Comparison of selected operating modes}
VL53L1X LIDAR sensor has an adjustable timing budget from 18.5ms all the way to 1 second, that 
determines the maximum time a ranging operation can take. To see the effect of timing budget with 
different ROI setups and distance modes, 4 timing budgets have been selected. 

With 18.5ms budget the sensor operates on the highest possible measurement frequency of 50Hz. This
can only be achieved in short distance mode without the possibility of modifying the ROI. The second
selected budget is 33ms, that is the lowest possible value to be used with long distance preset.
140ms is the lowest value that can provide measurements up to 4 meters. Lastly 200ms budget is 
selected to see how a higher timing budget affects accuracy. It is also the value used in the 
VL53L1X datasheet\cite{VL53L1XDatasheet} to demonstrate ranging accuracy.

The calculated average distance and standard deviation against the real distance can be seen on 
figure \ref{fig:vl53l1x_meas_opmodes}, std separatle is on \ref{fig:vl53l1x_meas_opmodes_std}. 
The measured sampling time accordingly is visible on figure \ref{fig:vl53l1x_meas_opmodes_sampling}. 

Based on the completed measurements, it can be seen that sampling time is independent from the
distance preset in use and is directly proportional to the number of ROIs in a scan and the 
timing budget. 50Hz sampling rate is not achieved even with 18.5ms timing budget, because 
the LIDAR was used in single shot mode and each measurement needs to be triggered by the MCU.
Sampling time can be increased for setups with 1x1 resolutions by switching to continuous 
measurement mode.

In every setup on each distance the most accurate measurement is always with
resolution 1x1. By increasing the resolution, therefore lowering the receiver SPAD array size,
the measured distance starts to deviate from the real distance and STD increases.This can be
seen on 2.5m distance with medium preset. Long distance preset however produces more accurate 
measurements even on 3m, so it is preferred over medium preset.

Measurements with long distance preset and 140ms timing budget follows the real distances
even on 3 meters, but starts to deviate on 3.5 meters with 2x2 resolution and above. Raising
the timing budget to 200ms reduces the error and standard deviation, but doesn't eliminate 
completely.


\begin{figure}[ht]
    \centering
    \includegraphics[width=150mm, keepaspectratio]{figures/vl53l1x_measurements_opmodes.png}
    \caption{VL53L1X measured distance STD and Average against real distance}
    \label{fig:vl53l1x_meas_opmodes}
\end{figure}
\begin{figure}[!h]
    \centering
    \includegraphics[width=150mm, keepaspectratio]{figures/vl53l1x_measurements_opmodes_sampling.png}
    \caption{VL53L1X range sampling time in different operation modes}
    \label{fig:vl53l1x_meas_opmodes_sampling}
\end{figure}

\newpage

\begin{figure}[!h]
    \centering
    \includegraphics[width=150mm, keepaspectratio]{figures/vl53l1x_measurements_opmodes_std.png}
    \caption{VL53L1X range standard deviation in different operation modes}
    \label{fig:vl53l1x_meas_opmodes_std}
\end{figure}

\subsection{Detailed distance measurements}
Based on the measurements described in the previous section, I chose a small set of LIDAR settings 
to further investigate and see how these behave on different distances. These settings are 
candidates to be used in simulations. The goal with the setting selection is to chose the ones
that may have greater affect the SLAM performance.

After the initial tests with Cartographer SLAM, it's safe to assume that sampling time shouldn't be
greater than 500ms. This is not a strict threshold, but with a higher sampling time, the algorithm 
would have a hard time to follow the position of the drone and insert new scans precisely. The second
assumption is that more points per scan increase the performance of scan insertion, because more points
create a more detailed and therefore more unique image. 

I chose 5 setups for further investigation, 4 with each resolution and the fastest one with 18.5ms 
timing budget. The lowest timing budget to be used with 4x4 resolution is 33ms, that is expected to be
just under the previously described threshold of 500ms per scan. The same budget is chosen for 3x3 
resolution, while 2x2 has lower number of ranges per scan so a higher budget, 70ms is selected to 
have more accurate measurements. As for 1x1 18.5ms and 140ms timing budgets are selected to see
the difference between a faster and a slower setup.

Each setup has been has been measured on distances starting from 0.5m to 4m with a step size
of 0.5m. The measurements can be seen on figures \ref{fig:vl53l1x_meas_detailed_dist},
\ref{fig:vl53l1x_meas_detailed_std}, \ref{fig:vl53l1x_meas_detailed_ts}. In the end
all setups turned out to have a lower sampling time than 500ms. It is interesting, that
sampling time turned out to be higher on smaller distances and lower on high distances.
This might be because the internal algorithm of VL53L1X sensor does longer measurements
to reassure that these ranges are not artifacts coming from reflections or crosstalk.

As expected the setup with 1x1 resolution and 140ms timing budget can range the farthest 
with only 9mm standard deviation. The setup with 2x2 resolution deviates from the real 
distance by 16cm on 3.5m, but is still accurate on 3m. 
The setups with 3x3 and 4x4 resolutions can measure up to 2.5m, but deviate on farther 
measurements. 

\begin{figure}[!h]
    \centering
	\includegraphics[width=115mm, keepaspectratio]{figures/vl53l1x_measurements_02_dist.png}
    \caption{Detailed distance measurements [mm]}
    \label{fig:vl53l1x_meas_detailed_dist}
\end{figure}

\begin{figure}[!h]
    \centering
	\includegraphics[width=115mm, keepaspectratio]{figures/vl53l1x_measurements_02_std.png}
    \caption{Standard deviation of selected measurements [mm]}
    \label{fig:vl53l1x_meas_detailed_std}
\end{figure}

\newpage

\begin{figure}[!h]
    \centering
	\includegraphics[width=115mm, keepaspectratio]{figures/vl53l1x_measurements_02_ts.png}
    \caption{Sampling time of selected measurements [s]}
    \label{fig:vl53l1x_meas_detailed_ts}
\end{figure}



\subsection{Detailed measurements with the fastest setup}
18.5ms timing budget with short distance preset can produce the fastest ranging measurements 
up to 1.6m according to the datasheet. The short preset also has the best ambient light 
immunity, a favorable quality. Due to these attributes I have decided to do more measurements
using these settings in combination with all resolutions.

Surprisingly the sensor with these settings was able to measure up to 2m with only 7mm 
standard deviation. Above 2m no ranges were successful, the sensor always reported 0 distance 
instead.

In comparison to the previous results the sampling time for each resolution has decreased 
significantly. In case of 4x4 resolution, the sampling time has decreased from 390ms to
265ms and the maximum distance from 2.5m to about 1m. The increase in update rate might be 
beneficial for the SLAM algorithm.

Surprisingly the update rate for 1x1 resolution reached 56Hz, that is higher than the 
maximum update rate according to the datasheet. The reason for the increased update rate
is that 50Hz was calculated using continuous measurement mode that places a 1.5ms delay
between ranges. In this scenario the device was used in single-shot mode and there was 
no delay between measurements. Although this method puts a high load on the host 
microcontroller that is not favorable in most applications.



\begin{figure}[!h]
    \centering
	\includegraphics[width=115mm, keepaspectratio]{figures/vl53l1x_measurements_03_dist.png}
    \caption{Detailed distance measurements [mm]}
    \label{fig:vl53l1x_meas_detailed_dist}
\end{figure}

\begin{figure}[!h]
    \centering
	\includegraphics[width=115mm, keepaspectratio]{figures/vl53l1x_measurements_03_std.png}
    \caption{Standard deviation of selected measurements [mm]}
    \label{fig:vl53l1x_meas_detailed_std}
\end{figure}


\begin{figure}[!h]
    \centering
	\includegraphics[width=115mm, keepaspectratio]{figures/vl53l1x_measurements_03_ts.png}
    \caption{Sampling time of selected measurements [s]}
    \label{fig:vl53l1x_meas_detailed_ts}
\end{figure}

\newpage

\section{2D SLAM evaluation}
During the evaluation both in 2D and 3D the same collected data will be used. The length 
of the collected rosbag is 144 seconds and contains all messages coming from all nodes on all
topics. The LIDAR distance measurements are published on two PointCloud topics on 30Hz each
and IMU data is published by PX4 flight controller stack on 50Hz.
The ground-truth pose data is extracted from the original dataset into a csv file and will 
be used for trajectory comparison in all scenarios. The original rosbag is then filtered 
to simulate a number of VL53L1X sensors with selected parameters. The filtered bags only 
contain the converted PointCloud2 and IMU besides the necessary clock messages.

The evaluation of Cartographer SLAM happens in incremental steps. It's unclear what parameters
affect the performance the most, so instead of applying all of them at once, I chose to introduce
these LIDAR parameters incrementally one by one to see the effects of them independently 
and work towards a complete set of parameters. 

In the first simulation only converted but unfiltered range data is used, that has the 
maximum possible sampling rate, 4m maximum distance and 128x128 resolution in total of 
the top and bottom hemispheres. This will produce the most accurate map and localization 
estimates, it is unlikely that any down-sampled dataset will produce better results.

As the second step the effect of the resolution is tested. 13 LIDAR sensors are placed
evenly on the horizontal axis and their resolution is set to 4x4 first and lowered to 3x3,
2x2 and 1x1. The sampling rate and maximum distance parameters are left unchanged.

To investigate the effect of the sampling rate, the resolution with the best performance 
from the previous step is used, but with the sampling rate of the actual sensor. Finally
the maximum distance is lowered, while keeping the same layout of the sensors.

After introducing all parameters the number of sensors is lowered until the lowest number 
sensors is found, that is still capable of producing a decent quality map.


\subsection{Unfiltered data}
In this step the range measurements inside the collected rosbag are converted to PointCloud2 
without filtering and get written to a new bag. The LIDAR ranges visualized in 
Rviz can be seen on figure \ref{fig:01_maxed_lidar} to demonstrate the scan resolution. 

\begin{figure}[!h]
    \centering
	\includegraphics[width=70mm, keepaspectratio]{figures/01_maxed_lidar.png}
    \caption{Visualization of unfiltered LIDAR measurements maximized on 4 meters}
    \label{fig:01_maxed_lidar}
\end{figure}

Cartographer in 2D mode projects all points inside a scan to the horizontal plane before 
insertion and therefore it is not advisable to include points that are coming from ranges 
that are hitting the floor or the ceiling. Only points that are coming from reflections 
of objects should be included in the scans and saturated LIDAR measurements should be 
discarded. During the bandwidth filter step, Cartographer filters the points and only 
inserts the ones inside user set thresholds, others are discarded.

To exclude points coming from unwanted elevations or saturation, 4 parameters are 
adjusted in the configuration file: min\_z, max\_z to set the interval on z axis
and min\_range, max\_range to set the range length interval. I have set min\_z and 
max\_z values to -10cm and 50cm, min\_range and max\_range to 40cm and 370cm accordingly. 
These settings proved to be working as expected and inserted ranges of the walls of 
the building. Since scans of the whole sphere are published on two topics, these need to be 
assembled into a single point cloud. This is done by Cartographer and is enabled by
setting num\_accumulated\_range\_data to 2.

IMU usage is enabled using the use\_imu\_data parameter and IMU data will be used as an 
initial guess for the pose of the scan for insertion. Cartographer samples the 
accelerometer values for a certain period of time to determine the direction of gravity.
The quadcopter changes pitch and roll angles quickly, so imu\_gravity\_time\_constant is 
set to 0.5 seconds to enable the algorithm to follow quick movements.

After setting up the basic settings for interfacing Cartographer, the actual tuning of 
the SLAM algorithm can be started. First the submap size need to be determined, that 
depends on the sampling rate of the LIDAR sensor. It is important because a new submap 
is built using constraints against the last two inserted submaps. 
Setting submap size low will cause submaps to drift 
or inadequate rotation due to lack of reference points. On the other hand setting submap
size high doesn't allow global SLAM thread to rearrange submaps and calculate loop closures
effectively. 

\begin{figure}[!hb]
    \centering
	$\vcenter{\hbox{\includegraphics[height=70mm, keepaspectratio]{figures/01_SLAM_process_1.png}}}$
    $\vcenter{\hbox{\includegraphics[height=70mm, keepaspectratio]{figures/01_SLAM_process_2.png}}}$
    \caption{2D SLAM map building on the left and complete map on the right}
    \label{fig:01_2d_slam_mapping}
\end{figure}

For tuning local SLAM, global SLAM is disabled. In this case I found that lowering 
translation\_weight and rotation\_weight under ceres scan matcher options increase the
mapping quality. The submap size is set to 90 ranges that is a bit too dense, but
due to the high sampling frequency and resolution it still created an adequate map
as seen on figure \ref{fig:01_2d_slam_mapping}. Empty spaces are with white color and
inserted scans are with black. The green points on the visualization are the points 
from the last inserted scan and the small coordinate systems are at the pose where 
a submap has been completed.

Corners are sharp, walls are straight and even small details like columns are visible 
on the final map. The big room on the top right of the map has three big windows and the drone
was flying about in the height of them and that's the reason for the high quantity of
empty space around this area. The algorithm was unable to insert points of the walls
in between windows.

Because there is no noise added to ranges, even without global SLAM, a decent quality 
map can be built. If global SLAM is enabled, the linear\_search\_window parameter needs
to be set to small, because the amount of drift of submaps is low. I have set the search 
window to 25cm, so submaps cannot be moved further than 25cm. If it is left unchanged,
submaps in range of 15 meters can be pulled together and would mess up the map.

\begin{figure}[!h]
    \centering
	$\vcenter{\hbox{\includegraphics[height=65mm, keepaspectratio]{figures/01_trajectory.png}}}$
    $\vcenter{\hbox{\includegraphics[height=65mm, keepaspectratio]{figures/01_trajectory_coordinates.png}}}$
    \caption{2D SLAM extracted trajectory against ground truth}
    \label{fig:01_trajectory}
\end{figure}

The extracted trajectory closely follows the ground truth trajectory as seen on figure 
\ref{fig:01_trajectory}. The RMS error on x axis is 24.6cm and a bit less 17cm on y axis,
resulting in a cumulated 41.6cm RMS error.

\begin{figure}[!h]
    \centering
	\includegraphics[height=65mm, keepaspectratio]{figures/01_trajectory_error.png}
    \caption{Trajectory error on each axis}
    \label{fig:01_trajectory_error}
\end{figure}

Figure \ref{fig:01_trajectory_error} shows the absolute error on the axes separately. The error 
never goes above 1 meter on either axis and the fact that it always returns to 0 shows,
that there is no drift in the pose estimation. It can also be seen on figure 
\ref{fig:01_trajectory}, because on the way back the drones follows the same path
and returns to the starting point.

\subsection{2D SLAM with 4x4 resolution}
In this scenario, the original rosbag is filtered to simulate 13 LIDAR sensors placed
evenly on the horizontal axis as described in \ref{sect:lidar_layout_plan}, each with
4x4 resolution. The visualization of the point cloud from a single scan can be seen on
figure \ref{fig:02_lidar_layout}.

\begin{figure}[!h]
    \centering
	\includegraphics[height=50mm, keepaspectratio]{figures/02_lidar_layout.png}
    \caption{Visualization of ranges from 13 sensors with 4x4 resolution}
    \label{fig:02_lidar_layout}
\end{figure}

\begin{figure}[!h]
    \centering
	$\vcenter{\hbox{\includegraphics[height=55mm, keepaspectratio]{figures/02_before_loop_closure.png}}}$
    $\vcenter{\hbox{\includegraphics[height=55mm, keepaspectratio]{figures/02_after_loop_closure.png}}}$
    \caption{Map before and after tuning}
    \label{fig:02_map}
\end{figure}


\subsection{2D SLAM with 3x3 resolution}
TODO


\section{3D SLAM evaluation}
TODO
\subsection{Unfiltered data}
TODO
\subsection{1x1 resolution}
TODO
\subsection{4x4 resolution}
TODO